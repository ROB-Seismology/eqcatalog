{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declustering applied to the Rott 2021 sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "## ROB-specific modules\n",
    "import mapping.layeredbasemap as lbm\n",
    "import eqcatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read earthquake sequence from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021, 1, 1)\n",
    "cat = eqcatalog.rob.query_local_eq_catalog(start_date=start_date,\n",
    "                                           region=(6.0, 6.4, 50.58, 50.875))\n",
    "cat.name = 'Rott sequence'\n",
    "cat.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 1 January 2021, a seismic sequence is occurring in the border region of Belgium and Germany. After 2 months, 129 events have occurred, ranging in magnitude ($M_L$) between -1.4 and 2.6. The mainshock ($M_L=2.6$) occurred on the 2nd day, but another $M_L=2.6$ earthquake occurred on day 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.subselect(Mmin=2.6, Mtype='ML').print_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map shows 2 spatial clusters: one around Rott in the SW, and the other around Eschweiler in the NE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color is by age (blue = oldest, red = most recent)\n",
    "color = lbm.ThematicStyleColormap('jet', value_key='year', add_legend=False)\n",
    "cat.plot_map(resolution='h', edge_color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.plot_time_magnitude(Mtype='ML', xtick_rotation=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot magnitude-frequency distribution. Completeness magnitude can be estimated as:\n",
    "* $M_L:$ 0.8 (0.2 if you are optimistic)\n",
    "* $M_W:$ 1.0 (0.4 if you are optimistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: OpenQuake MFDs do not support negative magnitudes...\n",
    "min_mag, max_mag = 0., 3\n",
    "bin_width = 0.2\n",
    "for Mtype in ('MW', 'ML'):\n",
    "    Mrelation = {}\n",
    "    if Mtype == 'MW':\n",
    "        Mrelation = {'ML': 'GruenthalEtAl2009'}\n",
    "    completeness = cat.get_uniform_completeness(min_mag, Mtype=Mtype)\n",
    "    seq_mfd = cat.get_incremental_mfd(min_mag, max_mag, bin_width, Mtype=Mtype,\n",
    "                                      Mrelation=Mrelation, completeness=completeness)\n",
    "    seq_mfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declustering analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if different declustering windows/methods identify sequence as 1 cluster. Note that all declustering methods are based on $M_W$, so we need a conversion from $M_L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mrelation = {'ML': 'GruenthalEtAl2009'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linked-window method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we test the linked-window method. This is a variant of the original windowing method of Gardner & Knopoff, but taking into account the combined space/time windows of all earthquakes in the cluster rather than only the mainshock. Ignoring or taking into account location errors does not change much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_method = eqcatalog.declustering.LinkedWindowMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_dc_results = {}\n",
    "for dc_window_name in ('GardnerKnopoff1974', 'Uhrhammer1986', 'Gruenthal2009'):\n",
    "    print(dc_window_name)\n",
    "    dc_window = eqcatalog.declustering.get_window_by_name(dc_window_name)\n",
    "    dc_result = dc_method.analyze_clusters(cat, dc_window, Mrelation,\n",
    "                                          ignore_location_errors=False)\n",
    "    dc_result.print_info()\n",
    "    lw_dc_results[dc_window_name] = dc_result\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A map of the clusters obtained with the Gr√ºnthal window definitions shows that the identified clusters overlap both areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_result = lw_dc_results['Gruenthal2009']\n",
    "catalogs = [cluster.to_catalog() for cluster in dc_result.get_clusters()]\n",
    "catalogs.append(dc_result.get_unclustered_events())\n",
    "labels = ['Cluster #%d' % i for i in range(dc_result.get_num_clusters())]\n",
    "labels.append('Unclustered')\n",
    "cm = matplotlib.cm.rainbow\n",
    "colors = [cm(i) for i in np.linspace(0, 1, len(catalogs))]\n",
    "eqcatalog.plot.plot_map(catalogs, labels=labels, edge_colors=colors, resolution='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_result.get_unclustered_events().print_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasenberg method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the Reasenberg declustering method. Note the strong sensitivity to location errors! On the other hand, the $xmeff$ parameter does not seem to have a strong influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the window definition, it is possible to adjust:\n",
    "## - rfact: number of crack radii (default: 10)\n",
    "## - dsigma: stress drop in bars (default: 30)\n",
    "## - rmax: max. interaction distance in km (default: 30)\n",
    "## - tau_min: min. length of time window in minutes (default: 2880 = 2 days)\n",
    "## - tau_max: max. length of time window in minutes (default: 144000 = 10 days)\n",
    "## - xmeff: \"effective\" lower magnitude cutoff (default: 1.5)\n",
    "## - xk: factor used to raise xmeff (default: 0.5)\n",
    "## - p1: confidence level (default: 0.99)\n",
    "dc_method = eqcatalog.declustering.ReasenbergMethod()\n",
    "for ignore_location_errors in (True, False):\n",
    "    if ignore_location_errors:\n",
    "        xmeff_values = [1.0]\n",
    "    else:\n",
    "        xmeff_values = [0.4, 1.0, 1.5]\n",
    "    for xmeff in xmeff_values:\n",
    "        dc_window = eqcatalog.declustering.Reasenberg1985Window(dsigma=30, xmeff=xmeff)\n",
    "        dc_result = dc_method.analyze_clusters(cat, Mrelation, dc_window,\n",
    "                                               ignore_location_errors=ignore_location_errors)\n",
    "        print('Reasenberg1985 (ignore_location_errors=%s, xmeff=%.1f)'\n",
    "              % (ignore_location_errors, xmeff))\n",
    "        dc_result.print_info()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_result.get_unclustered_events().print_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When location errors are taken into account, the Reasenberg method identifies two main clusters that are separated in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs = [cluster.to_catalog() for cluster in dc_result.get_clusters()]\n",
    "catalogs.append(dc_result.get_unclustered_events())\n",
    "labels = ['Cluster #%d' % i for i in range(dc_result.get_num_clusters())]\n",
    "labels.append('Unclustered')\n",
    "cm = matplotlib.cm.rainbow\n",
    "colors = [cm(i) for i in np.linspace(0, 1, len(catalogs))]\n",
    "eqcatalog.plot.plot_map(catalogs, labels=labels, edge_colors=colors, resolution='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omori-law fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the optimistic value for the completeness magnitude Mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mc = 0.2\n",
    "#Mc = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate mainshock from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainshock = cat.get_event_by_id(11630)\n",
    "Mm = mainshock.ML\n",
    "mainshock.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate aftershocks from cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dc_result.get_cluster_by_eq(mainshock)\n",
    "aftershocks = cluster.get_aftershocks()\n",
    "aftershocks.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply completeness magnitude constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_aftershocks = aftershocks.subselect(Mmin=Mc, Mtype='ML')\n",
    "print(len(cc_aftershocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine elapsed times (in days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_time_deltas = cc_aftershocks.get_time_deltas(mainshock.datetime)\n",
    "as_time_deltas = eqcatalog.time.fractional_time_delta(as_time_deltas, 'D')\n",
    "as_time_deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate parameters K, c, p of Omori law based on elapsed times since mainshock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(K1, c1, p1) = eqcatalog.omori.estimate_omori_params(as_time_deltas)\n",
    "(K1, c1, p1), _, _ = eqcatalog.omori.OmoriLaw.fit_cumulative(as_time_deltas,\n",
    "                                                             np.arange(len(as_time_deltas)))\n",
    "print(K1, c1, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Omori law. Note that value of K depends on completeness magnitude and mainshock magnitude, so these are inherent properties of the Omori law! Default time unit is days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omlaw = eqcatalog.omori.OmoriLaw(K1, c1, p1, Mc, Mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot cumulative number of aftershocks versus time. Different colors correspond to different clusters identified with the linked-window method (Gr√ºnthal window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "num_days = (today - start_date).days\n",
    "x_values = np.linspace(0, num_days, 100)\n",
    "marker_sizes = ((np.array([eq.ML for eq in cc_aftershocks]) - Mc) + 2)**2\n",
    "observed_cluster_idxs = [lw_dc_results['Gruenthal2009'].get_cluster_by_eq(eq).ID\n",
    "                         for eq in cc_aftershocks]\n",
    "unique_cluster_idxs = np.unique(observed_cluster_idxs)\n",
    "cm = matplotlib.cm.rainbow\n",
    "colors = [cm(i) for i in np.linspace(0, 1, len(unique_cluster_idxs))]\n",
    "label = 'Omori fit ($M_c=%.1f$)' % Mc\n",
    "omlaw.plot_cumulative(x_values, observed_delta_t=as_time_deltas, xscaling='lin',\n",
    "                      observed_marker_sizes=marker_sizes, observed_marker='o',\n",
    "                      observed_cluster_colors=colors,\n",
    "                      observed_cluster_idxs=observed_cluster_idxs, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
